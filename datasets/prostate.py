import os
import glob
import pickle
import torch
from torch_geometric.data import Dataset
from torch_geometric.data import Data, DataListLoader,DataLoader
from torch_geometric.nn import radius_graph
import random
import sys
import os
import csv

import lmdb
import numpy as np
from tqdm import tqdm

from torch.nn.functional import adaptive_avg_pool1d

#sys.path.append(os.getcwd())
#from setting import CrossValidSetting
#from mean_std import MEAN_STD


#mean = [0.0630, 0.0511, 0.0442, 0.0729, 0.0440, 0.0506, 0.0614, 0.0603, 0.0770,
#        0.0625, 0.0680, 0.0423, 0.0883, 0.0547, 0.0607, 0.0568, 0.0604, 0.0601,
#        0.0518, 0.0311, 0.0621, 0.0596, 0.0478, 0.0701, 0.0641, 0.0400, 0.0467,
#        0.0858, 0.0430, 0.0751, 0.0539, 0.0349, 0.0596, 0.0584, 0.0751, 0.0612,
#        0.0514, 0.0639, 0.0533, 0.0604, 0.0507, 0.0596, 0.0612, 0.0578, 0.0729,
#        0.0623, 0.0550, 0.0383, 0.0616, 0.0373, 0.0473, 0.0431, 0.0527, 0.0533,
#        0.0314, 0.0422, 0.0723, 0.0417, 0.0609, 0.0739, 0.0508, 0.0526, 0.0448,
#        0.0430, 0.0500, 0.0672, 0.0767, 0.0493, 0.0584, 0.0590, 0.0450, 0.0550,
#        0.0516, 0.0507, 0.0554, 0.0645, 0.0505, 0.0294, 0.0518, 0.0496, 0.0495,
#        0.0381, 0.0589, 0.0583, 0.0306, 0.0485, 0.0718, 0.0546, 0.0675, 0.0479,
#        0.0506, 0.0506, 0.0652, 0.0574, 0.0418, 0.0673, 0.0405, 0.0978, 0.0515,
#        0.0359, 0.0480, 0.0408, 0.0701, 0.0491, 0.0506, 0.0286, 0.0654, 0.0667,
#        0.0709, 0.0329, 0.0427, 0.0549, 0.0490, 0.0337, 0.0457, 0.0557, 0.0472,
#        0.0575, 0.0632, 0.0761, 0.0327, 0.0445, 0.0510, 0.0304, 0.0543, 0.0603,
#        0.0522, 0.0438, 0.0702, 0.0644, 0.0502, 0.0554, 0.0757, 0.0502, 0.0410,
#        0.0659, 0.0469, 0.0473, 0.0329, 0.0537, 0.0546, 0.0802, 0.0560, 0.0671,
#        0.0593, 0.0511, 0.0425, 0.0568, 0.0601, 0.0605, 0.0487, 0.0527, 0.0419,
#        0.0554, 0.0571, 0.0479, 0.0606, 0.0380, 0.0523, 0.0443, 0.0447, 0.0503,
#        0.0357, 0.0652, 0.0640, 0.0537, 0.0802, 0.0536, 0.0385, 0.0559, 0.0543,
#        0.0423, 0.0465, 0.0610, 0.0425, 0.0334, 0.0585, 0.0593, 0.0514, 0.0441,
#        0.0515, 0.0521, 0.0405, 0.0387, 0.0520, 0.0326, 0.0540, 0.0489, 0.0443,
#        0.0487, 0.0658, 0.0697, 0.0592, 0.0396, 0.0621, 0.0751, 0.0418, 0.0466,
#        0.0313, 0.0560, 0.0400, 0.0520, 0.0659, 0.0557, 0.0585, 0.0581, 0.0576,
#        0.0501, 0.0314, 0.0595, 0.0554, 0.0433, 0.0537, 0.0498, 0.0433, 0.0444,
#        0.0438, 0.0464, 0.0846, 0.0628, 0.0667, 0.0576, 0.0550, 0.0443, 0.0676,
#        0.0418, 0.0612, 0.0542, 0.0480, 0.0523, 0.0421, 0.0968, 0.0679, 0.0449,
#        0.0469, 0.0671, 0.0620, 0.0763, 0.0663, 0.0602, 0.0333, 0.0566, 0.0359,
#        0.0352, 0.0352, 0.0439, 0.0349, 0.0764, 0.0278, 0.0536, 0.0405, 0.0524,
#        0.0588, 0.0476, 0.0560, 0.0625, 0.0413, 0.0596, 0.0593, 0.0331, 0.0308,
#        0.0700, 0.0471, 0.0490, 0.0540, 0.0502, 0.0992, 0.0619, 0.0482, 0.0625,
#        0.0619, 0.0447, 0.0577, 0.0793, 0.0828, 0.0512, 0.0633, 0.0743, 0.0574,
#        0.0575, 0.0425, 0.0653, 0.0422, 0.0480, 0.0451, 0.0612, 0.0662, 0.0502,
#        0.0665, 0.0315, 0.0548, 0.0314, 0.0417, 0.0354, 0.0864, 0.0476, 0.0501,
#        0.0517, 0.0520, 0.0746, 0.0610, 0.0750, 0.0479, 0.0455, 0.0517, 0.0384,
#        0.0562, 0.0591, 0.0674, 0.0607, 0.0483, 0.0465, 0.0514, 0.0555, 0.0506,
#        0.0464, 0.0734, 0.0500, 0.0412, 0.0679, 0.0557, 0.0580, 0.0515, 0.0391,
#        0.0498, 0.0678, 0.0574, 0.0502, 0.0594, 0.0582, 0.0703, 0.0715, 0.0488,
#        0.0497, 0.0518, 0.0459, 0.0473, 0.0647, 0.0446, 0.0421, 0.0374, 0.0524,
#        0.0793, 0.0420, 0.0492, 0.0449, 0.0362, 0.0492, 0.0638, 0.0696, 0.0555,
#        0.0610, 0.0427, 0.0657, 0.0452, 0.0593, 0.0467, 0.0510, 0.0395, 0.0433,
#        0.0681, 0.0860, 0.0564, 0.0352, 0.0501, 0.0766, 0.0483, 0.0524, 0.0536,
#        0.0371, 0.0430, 0.0387, 0.0543, 0.0534, 0.0464, 0.0902, 0.0431, 0.0612,
#        0.0428, 0.0843, 0.0525, 0.0503, 0.0622, 0.0483, 0.0627, 0.0550, 0.0671,
#        0.0422, 0.0685, 0.0585, 0.0540, 0.0300, 0.0374, 0.0514, 0.0467, 0.0396,
#        0.0576, 0.0588, 0.0382, 0.0400, 0.0652, 0.0707, 0.0735, 0.0598, 0.0423,
#        0.0474, 0.0515, 0.0572, 0.0482, 0.0762, 0.0638, 0.0563, 0.0652, 0.0519,
#        0.0557, 0.0630, 0.0518, 0.0680, 0.0507, 0.0682, 0.0481, 0.0534, 0.0492,
#        0.0514, 0.0482, 0.0482, 0.0642, 0.0614, 0.0408, 0.0351, 0.0519, 0.0633,
#        0.0790, 0.0649, 0.0377, 0.0464, 0.0412, 0.0477, 0.0321, 0.0444, 0.0409,
#        0.0358, 0.0371, 0.0467, 0.0550, 0.0585, 0.0454, 0.0374, 0.0516, 0.0877,
#        0.0522, 0.0456, 0.0398, 0.0674, 0.0406, 0.0505, 0.0441, 0.0511, 0.0440,
#        0.0831, 0.0523, 0.0634, 0.0355, 0.0571, 0.0648, 0.0508, 0.0489, 0.0557,
#        0.0379, 0.0577, 0.0389, 0.0641, 0.0653, 0.0517, 0.0489, 0.0557, 0.0618,
#        0.0530, 0.0508, 0.0577, 0.0442, 0.0401, 0.0481, 0.0487, 0.0722, 0.0445,
#        0.0305, 0.0495, 0.0672, 0.0485, 0.0532, 0.0382, 0.0605, 0.0674, 0.0417,
#        0.0447, 0.0698, 0.0512, 0.0450, 0.0600, 0.0732, 0.0561, 0.0493, 0.0526,
#        0.0987, 0.0467, 0.0360, 0.0408, 0.0629, 0.0699, 0.0464, 0.0339]
#std = [0.0460, 0.0253, 0.0147, 0.0248, 0.0253, 0.0220, 0.0245, 0.0285, 0.0527,
#        0.0371, 0.0169, 0.0108, 0.0294, 0.0191, 0.0314, 0.0316, 0.0392, 0.0326,
#        0.0199, 0.0341, 0.0185, 0.0212, 0.0270, 0.0448, 0.0372, 0.0235, 0.0198,
#        0.0360, 0.0268, 0.0261, 0.0125, 0.0156, 0.0153, 0.0276, 0.0544, 0.0317,
#        0.0083, 0.0269, 0.0375, 0.0128, 0.0253, 0.0247, 0.0139, 0.0196, 0.0414,
#        0.0139, 0.0171, 0.0285, 0.0114, 0.0271, 0.0266, 0.0093, 0.0300, 0.0295,
#        0.0203, 0.0305, 0.0286, 0.0263, 0.0223, 0.0238, 0.0190, 0.0243, 0.0184,
#        0.0304, 0.0285, 0.0479, 0.0142, 0.0310, 0.0355, 0.0239, 0.0109, 0.0366,
#        0.0335, 0.0141, 0.0192, 0.0192, 0.0253, 0.0165, 0.0360, 0.0411, 0.0142,
#        0.0130, 0.0164, 0.0261, 0.0233, 0.0223, 0.0204, 0.0237, 0.0373, 0.0210,
#        0.0242, 0.0343, 0.0267, 0.0243, 0.0153, 0.0177, 0.0107, 0.0671, 0.0318,
#        0.0107, 0.0155, 0.0311, 0.0280, 0.0218, 0.0121, 0.0268, 0.0281, 0.0435,
#        0.0213, 0.0225, 0.0240, 0.0169, 0.0390, 0.0190, 0.0105, 0.0134, 0.0245,
#        0.0243, 0.0250, 0.0297, 0.0132, 0.0239, 0.0304, 0.0216, 0.0218, 0.0166,
#        0.0258, 0.0131, 0.0406, 0.0118, 0.0325, 0.0346, 0.0424, 0.0315, 0.0215,
#        0.0415, 0.0286, 0.0252, 0.0173, 0.0266, 0.0306, 0.0396, 0.0469, 0.0354,
#        0.0311, 0.0348, 0.0436, 0.0174, 0.0290, 0.0262, 0.0266, 0.0200, 0.0390,
#        0.0213, 0.0206, 0.0129, 0.0092, 0.0203, 0.0245, 0.0250, 0.0242, 0.0346,
#        0.0093, 0.0323, 0.0422, 0.0179, 0.0218, 0.0306, 0.0242, 0.0223, 0.0192,
#        0.0188, 0.0239, 0.0273, 0.0200, 0.0155, 0.0159, 0.0325, 0.0254, 0.0246,
#        0.0247, 0.0161, 0.0095, 0.0148, 0.0255, 0.0091, 0.0342, 0.0168, 0.0265,
#        0.0232, 0.0146, 0.0218, 0.0359, 0.0286, 0.0428, 0.0211, 0.0219, 0.0220,
#        0.0061, 0.0279, 0.0238, 0.0173, 0.0311, 0.0139, 0.0201, 0.0169, 0.0185,
#        0.0367, 0.0268, 0.0442, 0.0251, 0.0213, 0.0259, 0.0431, 0.0229, 0.0227,
#        0.0390, 0.0211, 0.0143, 0.0370, 0.0339, 0.0184, 0.0292, 0.0102, 0.0372,
#        0.0281, 0.0223, 0.0231, 0.0345, 0.0215, 0.0244, 0.0345, 0.0175, 0.0121,
#        0.0180, 0.0355, 0.0335, 0.0408, 0.0435, 0.0207, 0.0107, 0.0255, 0.0403,
#        0.0300, 0.0169, 0.0172, 0.0204, 0.0120, 0.0123, 0.0181, 0.0297, 0.0377,
#        0.0284, 0.0163, 0.0248, 0.0502, 0.0231, 0.0437, 0.0323, 0.0158, 0.0268,
#        0.0488, 0.0270, 0.0293, 0.0303, 0.0321, 0.0420, 0.0180, 0.0249, 0.0302,
#        0.0197, 0.0226, 0.0175, 0.0470, 0.0470, 0.0319, 0.0266, 0.0378, 0.0341,
#        0.0198, 0.0239, 0.0298, 0.0133, 0.0107, 0.0251, 0.0329, 0.0354, 0.0320,
#        0.0462, 0.0202, 0.0314, 0.0226, 0.0121, 0.0210, 0.0573, 0.0143, 0.0224,
#        0.0214, 0.0189, 0.0356, 0.0287, 0.0308, 0.0236, 0.0307, 0.0282, 0.0164,
#        0.0259, 0.0344, 0.0294, 0.0363, 0.0184, 0.0199, 0.0174, 0.0372, 0.0352,
#        0.0230, 0.0446, 0.0370, 0.0234, 0.0287, 0.0458, 0.0242, 0.0209, 0.0165,
#        0.0274, 0.0285, 0.0119, 0.0201, 0.0233, 0.0307, 0.0348, 0.0215, 0.0237,
#        0.0283, 0.0143, 0.0219, 0.0284, 0.0283, 0.0175, 0.0271, 0.0196, 0.0259,
#        0.0290, 0.0223, 0.0199, 0.0212, 0.0154, 0.0250, 0.0348, 0.0232, 0.0272,
#        0.0281, 0.0079, 0.0361, 0.0171, 0.0326, 0.0165, 0.0406, 0.0246, 0.0240,
#        0.0304, 0.0335, 0.0322, 0.0137, 0.0305, 0.0509, 0.0198, 0.0356, 0.0382,
#        0.0193, 0.0210, 0.0150, 0.0311, 0.0267, 0.0438, 0.0271, 0.0136, 0.0385,
#        0.0176, 0.0255, 0.0197, 0.0187, 0.0274, 0.0241, 0.0446, 0.0419, 0.0139,
#        0.0162, 0.0321, 0.0547, 0.0269, 0.0062, 0.0271, 0.0325, 0.0196, 0.0193,
#        0.0155, 0.0375, 0.0074, 0.0168, 0.0287, 0.0224, 0.0195, 0.0363, 0.0228,
#        0.0320, 0.0206, 0.0318, 0.0094, 0.0134, 0.0276, 0.0147, 0.0184, 0.0289,
#        0.0341, 0.0186, 0.0344, 0.0246, 0.0186, 0.0435, 0.0236, 0.0303, 0.0202,
#        0.0247, 0.0243, 0.0331, 0.0212, 0.0227, 0.0096, 0.0180, 0.0269, 0.0283,
#        0.0380, 0.0145, 0.0111, 0.0227, 0.0271, 0.0177, 0.0130, 0.0225, 0.0118,
#        0.0183, 0.0131, 0.0185, 0.0264, 0.0123, 0.0236, 0.0236, 0.0279, 0.0302,
#        0.0268, 0.0261, 0.0241, 0.0244, 0.0144, 0.0191, 0.0234, 0.0267, 0.0344,
#        0.0463, 0.0259, 0.0301, 0.0289, 0.0225, 0.0220, 0.0308, 0.0454, 0.0288,
#        0.0347, 0.0283, 0.0240, 0.0247, 0.0317, 0.0328, 0.0324, 0.0351, 0.0351,
#        0.0202, 0.0347, 0.0210, 0.0118, 0.0221, 0.0344, 0.0177, 0.0347, 0.0144,
#        0.0182, 0.0188, 0.0420, 0.0431, 0.0201, 0.0145, 0.0206, 0.0353, 0.0240,
#        0.0271, 0.0278, 0.0251, 0.0188, 0.0239, 0.0214, 0.0363, 0.0270, 0.0268,
#        0.0402, 0.0173, 0.0127, 0.0216, 0.0246, 0.0220, 0.0305, 0.0164]

mean = [6.3039e-02, 5.1078e-02, 4.4181e-02, 7.2962e-02, 4.4039e-02, 5.0707e-02,
        6.1406e-02, 6.0387e-02, 7.7141e-02, 6.2593e-02, 6.8038e-02, 4.2335e-02,
        8.8251e-02, 5.4845e-02, 6.0708e-02, 5.6871e-02, 6.0402e-02, 6.0179e-02,
        5.1781e-02, 3.1081e-02, 6.2107e-02, 5.9691e-02, 4.7812e-02, 7.0224e-02,
        6.4160e-02, 4.0059e-02, 4.6730e-02, 8.5899e-02, 4.2958e-02, 7.5142e-02,
        5.4017e-02, 3.5008e-02, 5.9612e-02, 5.8476e-02, 7.5140e-02, 6.1241e-02,
        5.1442e-02, 6.3927e-02, 5.3349e-02, 6.0467e-02, 5.0754e-02, 5.9620e-02,
        6.1285e-02, 5.7869e-02, 7.2958e-02, 6.2358e-02, 5.5114e-02, 3.8302e-02,
        6.1633e-02, 3.7264e-02, 4.7347e-02, 4.3157e-02, 5.2705e-02, 5.3286e-02,
        3.1434e-02, 4.2173e-02, 7.2351e-02, 4.1789e-02, 6.0904e-02, 7.3976e-02,
        5.0859e-02, 5.2681e-02, 4.4836e-02, 4.3053e-02, 5.0110e-02, 6.7295e-02,
        7.6756e-02, 4.9331e-02, 5.8401e-02, 5.9049e-02, 4.5077e-02, 5.4971e-02,
        5.1600e-02, 5.0730e-02, 5.5492e-02, 6.4546e-02, 5.0487e-02, 2.9379e-02,
        5.1888e-02, 4.9608e-02, 4.9600e-02, 3.8082e-02, 5.8962e-02, 5.8351e-02,
        3.0606e-02, 4.8589e-02, 7.1891e-02, 5.4624e-02, 6.7531e-02, 4.7965e-02,
        5.0586e-02, 5.0591e-02, 6.5249e-02, 5.7415e-02, 4.1840e-02, 6.7327e-02,
        4.0527e-02, 9.7860e-02, 5.1577e-02, 3.5978e-02, 4.8086e-02, 4.0808e-02,
        7.0268e-02, 4.9165e-02, 5.0693e-02, 2.8619e-02, 6.5386e-02, 6.6732e-02,
        7.0935e-02, 3.2935e-02, 4.2656e-02, 5.4971e-02, 4.9046e-02, 3.3701e-02,
        4.5723e-02, 5.5695e-02, 4.7221e-02, 5.7536e-02, 6.3221e-02, 7.6085e-02,
        3.2755e-02, 4.4499e-02, 5.0980e-02, 3.0396e-02, 5.4361e-02, 6.0310e-02,
        5.2218e-02, 4.3864e-02, 7.0330e-02, 6.4530e-02, 5.0135e-02, 5.5433e-02,
        7.5853e-02, 5.0201e-02, 4.1037e-02, 6.5941e-02, 4.6939e-02, 4.7342e-02,
        3.2945e-02, 5.3756e-02, 5.4707e-02, 8.0296e-02, 5.6041e-02, 6.7165e-02,
        5.9338e-02, 5.1134e-02, 4.2553e-02, 5.6869e-02, 6.0151e-02, 6.0538e-02,
        4.8788e-02, 5.2730e-02, 4.2015e-02, 5.5452e-02, 5.7253e-02, 4.7943e-02,
        6.0665e-02, 3.8067e-02, 5.2354e-02, 4.4299e-02, 4.4798e-02, 5.0347e-02,
        3.5676e-02, 6.5233e-02, 6.4018e-02, 5.3700e-02, 8.0254e-02, 5.3660e-02,
        3.8523e-02, 5.6008e-02, 5.4314e-02, 4.2328e-02, 4.6493e-02, 6.1110e-02,
        4.2601e-02, 3.3433e-02, 5.8399e-02, 5.9428e-02, 5.1467e-02, 4.4172e-02,
        5.1598e-02, 5.2063e-02, 4.0481e-02, 3.8723e-02, 5.2052e-02, 3.2694e-02,
        5.4045e-02, 4.8933e-02, 4.4338e-02, 4.8832e-02, 6.5805e-02, 6.9737e-02,
        5.9263e-02, 3.9654e-02, 6.2106e-02, 7.5171e-02, 4.1885e-02, 4.6690e-02,
        3.1322e-02, 5.5966e-02, 3.9977e-02, 5.2014e-02, 6.5881e-02, 5.5717e-02,
        5.8595e-02, 5.8210e-02, 5.7656e-02, 5.0047e-02, 3.1482e-02, 5.9499e-02,
        5.5446e-02, 4.3338e-02, 5.3771e-02, 4.9810e-02, 4.3421e-02, 4.4361e-02,
        4.3797e-02, 4.6423e-02, 8.4707e-02, 6.2898e-02, 6.6800e-02, 5.7634e-02,
        5.5096e-02, 4.4385e-02, 6.7613e-02, 4.1890e-02, 6.1311e-02, 5.4211e-02,
        4.8009e-02, 5.2347e-02, 4.2109e-02, 9.6980e-02, 6.7940e-02, 4.4951e-02,
        4.6993e-02, 6.7197e-02, 6.2019e-02, 7.6417e-02, 6.6392e-02, 6.0257e-02,
        3.3295e-02, 5.6712e-02, 3.5916e-02, 3.5253e-02, 3.5210e-02, 4.3921e-02,
        3.4935e-02, 7.6456e-02, 2.7807e-02, 5.3614e-02, 4.0529e-02, 5.2432e-02,
        5.8847e-02, 4.7680e-02, 5.6080e-02, 6.2595e-02, 4.1330e-02, 5.9738e-02,
        5.9347e-02, 3.3105e-02, 3.0854e-02, 7.0030e-02, 4.7113e-02, 4.9019e-02,
        5.4107e-02, 5.0209e-02, 9.9218e-02, 6.1933e-02, 4.8185e-02, 6.2477e-02,
        6.1956e-02, 4.4713e-02, 5.7822e-02, 7.9346e-02, 8.2852e-02, 5.1268e-02,
        6.3407e-02, 7.4296e-02, 5.7538e-02, 5.7551e-02, 4.2518e-02, 6.5420e-02,
        4.2192e-02, 4.8028e-02, 4.5158e-02, 6.1311e-02, 6.6203e-02, 5.0189e-02,
        6.6632e-02, 3.1577e-02, 5.4919e-02, 3.1396e-02, 4.1677e-02, 3.5408e-02,
        8.6426e-02, 4.7710e-02, 5.0151e-02, 5.1749e-02, 5.1991e-02, 7.4727e-02,
        6.1124e-02, 7.5029e-02, 4.7990e-02, 4.5551e-02, 5.1743e-02, 3.8476e-02,
        5.6305e-02, 5.9082e-02, 6.7489e-02, 6.0898e-02, 4.8410e-02, 4.6493e-02,
        5.1455e-02, 5.5635e-02, 5.0628e-02, 4.6455e-02, 7.3483e-02, 4.9939e-02,
        4.1257e-02, 6.7915e-02, 5.5741e-02, 5.8083e-02, 5.1512e-02, 3.9155e-02,
        4.9799e-02, 6.7775e-02, 5.7424e-02, 5.0260e-02, 5.9432e-02, 5.8339e-02,
        7.0297e-02, 7.1633e-02, 4.8809e-02, 4.9767e-02, 5.1938e-02, 4.5929e-02,
        4.7345e-02, 6.4895e-02, 4.4647e-02, 4.2164e-02, 3.7383e-02, 5.2433e-02,
        7.9373e-02, 4.2018e-02, 4.9268e-02, 4.4924e-02, 3.6262e-02, 4.9263e-02,
        6.3817e-02, 6.9684e-02, 5.5593e-02, 6.1104e-02, 4.2757e-02, 6.5821e-02,
        4.5252e-02, 5.9344e-02, 4.6821e-02, 5.0989e-02, 3.9580e-02, 4.3301e-02,
        6.8120e-02, 8.6100e-02, 5.6456e-02, 3.5166e-02, 5.0151e-02, 7.6640e-02,
        4.8315e-02, 5.2372e-02, 5.3800e-02, 3.7145e-02, 4.3041e-02, 3.8787e-02,
        5.4375e-02, 5.3386e-02, 4.6501e-02, 9.0343e-02, 4.3128e-02, 6.1214e-02,
        4.2864e-02, 8.4327e-02, 5.2519e-02, 5.0405e-02, 6.2290e-02, 4.8317e-02,
        6.2756e-02, 5.5041e-02, 6.7197e-02, 4.2264e-02, 6.8550e-02, 5.8489e-02,
        5.4101e-02, 3.0055e-02, 3.7380e-02, 5.1483e-02, 4.6786e-02, 3.9674e-02,
        5.7704e-02, 5.8825e-02, 3.8279e-02, 4.0008e-02, 6.5271e-02, 7.0764e-02,
        7.3558e-02, 5.9871e-02, 4.2253e-02, 4.7395e-02, 5.1513e-02, 5.7226e-02,
        4.8249e-02, 7.6191e-02, 6.3819e-02, 5.6304e-02, 6.5245e-02, 5.1956e-02,
        5.5663e-02, 6.3020e-02, 5.1768e-02, 6.7979e-02, 5.0760e-02, 6.8220e-02,
        4.8153e-02, 5.3477e-02, 4.9179e-02, 5.1447e-02, 4.8321e-02, 4.8239e-02,
        6.4286e-02, 6.1406e-02, 4.0835e-02, 3.5093e-02, 5.2000e-02, 6.3370e-02,
        7.9142e-02, 6.4961e-02, 3.7731e-02, 4.6443e-02, 4.1214e-02, 4.7644e-02,
        3.2121e-02, 4.4456e-02, 4.0930e-02, 3.5867e-02, 3.7142e-02, 4.6731e-02,
        5.5042e-02, 5.8550e-02, 4.5385e-02, 3.7500e-02, 5.1670e-02, 8.7722e-02,
        5.2238e-02, 4.5677e-02, 3.9859e-02, 6.7540e-02, 4.0653e-02, 5.0585e-02,
        4.4143e-02, 5.1187e-02, 4.4050e-02, 8.3151e-02, 5.2372e-02, 6.3444e-02,
        3.5522e-02, 5.7202e-02, 6.4849e-02, 5.0853e-02, 4.8870e-02, 5.5795e-02,
        3.7846e-02, 5.7713e-02, 3.8998e-02, 6.4202e-02, 6.5363e-02, 5.1731e-02,
        4.8960e-02, 5.5753e-02, 6.1899e-02, 5.3069e-02, 5.0844e-02, 5.7772e-02,
        4.4218e-02, 4.0134e-02, 4.8154e-02, 4.8785e-02, 7.2237e-02, 4.4582e-02,
        3.0525e-02, 4.9548e-02, 6.7309e-02, 4.8452e-02, 5.3248e-02, 3.8276e-02,
        6.0566e-02, 6.7438e-02, 4.1731e-02, 4.4735e-02, 6.9923e-02, 5.1317e-02,
        4.4995e-02, 6.0032e-02, 7.3277e-02, 5.6175e-02, 4.9277e-02, 5.2592e-02,
        9.8883e-02, 4.6709e-02, 3.6039e-02, 4.0821e-02, 6.2943e-02, 6.9900e-02,
        4.6442e-02, 3.4013e-02, 7.9031e+02, 7.7442e+02]
std = [2.1493e-03, 6.5049e-04, 2.1906e-04, 6.3348e-04, 6.4822e-04, 4.9847e-04,
        6.2388e-04, 8.3213e-04, 2.8696e-03, 1.4042e-03, 2.9210e-04, 1.2083e-04,
        8.8801e-04, 3.7250e-04, 1.0228e-03, 1.0161e-03, 1.5558e-03, 1.0956e-03,
        4.0542e-04, 1.1868e-03, 3.5487e-04, 4.5711e-04, 7.4607e-04, 2.0421e-03,
        1.4151e-03, 5.5763e-04, 3.9821e-04, 1.3376e-03, 7.3444e-04, 7.0171e-04,
        1.6184e-04, 2.5165e-04, 2.3996e-04, 7.7288e-04, 3.0161e-03, 1.0224e-03,
        7.1882e-05, 7.3641e-04, 1.4295e-03, 1.6766e-04, 6.5435e-04, 6.2141e-04,
        2.0127e-04, 3.9005e-04, 1.7669e-03, 2.0069e-04, 2.9770e-04, 8.2574e-04,
        1.3554e-04, 7.5539e-04, 7.1802e-04, 8.8868e-05, 9.1184e-04, 8.9419e-04,
        4.3544e-04, 9.4708e-04, 8.4292e-04, 7.1570e-04, 5.0802e-04, 5.7728e-04,
        3.6910e-04, 6.0712e-04, 3.4981e-04, 9.4565e-04, 8.3301e-04, 2.3473e-03,
        2.1093e-04, 9.9390e-04, 1.2850e-03, 5.8671e-04, 1.2073e-04, 1.3717e-03,
        1.1476e-03, 2.0653e-04, 3.7538e-04, 3.8564e-04, 6.4995e-04, 2.7301e-04,
        1.3341e-03, 1.7253e-03, 2.0749e-04, 1.7499e-04, 2.7378e-04, 6.9084e-04,
        5.5451e-04, 5.0664e-04, 4.2203e-04, 5.7458e-04, 1.4268e-03, 4.4559e-04,
        6.0229e-04, 1.1941e-03, 7.3018e-04, 6.0504e-04, 2.3910e-04, 3.2103e-04,
        1.1910e-04, 4.6604e-03, 1.0356e-03, 1.1765e-04, 2.4442e-04, 9.8783e-04,
        8.0279e-04, 4.8749e-04, 1.5081e-04, 7.3804e-04, 8.0078e-04, 1.9234e-03,
        4.6538e-04, 5.1572e-04, 5.8456e-04, 2.8961e-04, 1.5398e-03, 3.7264e-04,
        1.1283e-04, 1.8735e-04, 6.3324e-04, 6.0148e-04, 6.4336e-04, 9.1091e-04,
        1.7795e-04, 5.8716e-04, 9.3559e-04, 4.7932e-04, 4.9727e-04, 2.8221e-04,
        6.7692e-04, 1.7497e-04, 1.6993e-03, 1.4658e-04, 1.0780e-03, 1.2405e-03,
        1.8434e-03, 1.0203e-03, 4.8774e-04, 1.7685e-03, 8.3715e-04, 6.5023e-04,
        3.0310e-04, 7.2638e-04, 9.5681e-04, 1.6022e-03, 2.2266e-03, 1.2832e-03,
        9.9414e-04, 1.2608e-03, 1.9388e-03, 3.1068e-04, 8.6315e-04, 7.0198e-04,
        7.2400e-04, 4.1185e-04, 1.5425e-03, 4.6550e-04, 4.3959e-04, 1.7248e-04,
        8.8222e-05, 4.1990e-04, 6.1021e-04, 6.4732e-04, 6.0486e-04, 1.2311e-03,
        8.8479e-05, 1.0724e-03, 1.8247e-03, 3.3232e-04, 4.8538e-04, 9.4896e-04,
        5.9641e-04, 5.1848e-04, 3.7508e-04, 3.6149e-04, 5.8001e-04, 7.5641e-04,
        4.0724e-04, 2.4706e-04, 2.6700e-04, 1.0911e-03, 6.6399e-04, 6.1768e-04,
        6.1895e-04, 2.6543e-04, 9.3687e-05, 2.2821e-04, 6.6440e-04, 8.4405e-05,
        1.2064e-03, 2.9058e-04, 7.1676e-04, 5.4478e-04, 2.1801e-04, 4.8434e-04,
        1.3132e-03, 8.3607e-04, 1.8811e-03, 4.5272e-04, 4.9243e-04, 4.9365e-04,
        3.8884e-05, 7.9504e-04, 5.7149e-04, 3.0560e-04, 9.8485e-04, 1.9743e-04,
        4.1590e-04, 2.9109e-04, 3.4908e-04, 1.3724e-03, 7.6424e-04, 1.9892e-03,
        6.5298e-04, 4.6037e-04, 6.8363e-04, 1.8877e-03, 5.4848e-04, 5.2482e-04,
        1.5596e-03, 4.5349e-04, 2.1509e-04, 1.4115e-03, 1.1880e-03, 3.4758e-04,
        8.6880e-04, 1.0697e-04, 1.4281e-03, 8.0950e-04, 5.0766e-04, 5.4923e-04,
        1.2218e-03, 4.7709e-04, 6.1672e-04, 1.2161e-03, 3.1198e-04, 1.5027e-04,
        3.2912e-04, 1.2860e-03, 1.1493e-03, 1.6980e-03, 1.9933e-03, 4.3956e-04,
        1.1705e-04, 6.6696e-04, 1.6511e-03, 9.1475e-04, 2.9001e-04, 3.0195e-04,
        4.2203e-04, 1.4862e-04, 1.5424e-04, 3.4328e-04, 8.9938e-04, 1.4535e-03,
        8.2515e-04, 2.7273e-04, 6.3097e-04, 2.6045e-03, 5.4577e-04, 1.9627e-03,
        1.0638e-03, 2.5581e-04, 7.3265e-04, 2.4472e-03, 7.5810e-04, 8.6979e-04,
        9.3249e-04, 1.0618e-03, 1.8070e-03, 3.3190e-04, 6.2932e-04, 9.3707e-04,
        3.9576e-04, 5.2373e-04, 3.1604e-04, 2.2611e-03, 2.2740e-03, 1.0431e-03,
        7.3304e-04, 1.4448e-03, 1.1964e-03, 4.0076e-04, 5.8622e-04, 9.0472e-04,
        1.8211e-04, 1.1828e-04, 6.4596e-04, 1.1131e-03, 1.2745e-03, 1.0387e-03,
        2.1856e-03, 4.1478e-04, 9.9909e-04, 5.2961e-04, 1.4903e-04, 4.4961e-04,
        3.3911e-03, 2.0719e-04, 5.0973e-04, 4.7437e-04, 3.6672e-04, 1.3059e-03,
        8.4290e-04, 9.7858e-04, 5.7619e-04, 9.5709e-04, 8.0659e-04, 2.7458e-04,
        7.0161e-04, 1.1995e-03, 8.7902e-04, 1.3607e-03, 3.4433e-04, 4.0830e-04,
        3.1301e-04, 1.4312e-03, 1.2594e-03, 5.4880e-04, 2.0380e-03, 1.3923e-03,
        5.5612e-04, 8.3744e-04, 2.1457e-03, 5.9948e-04, 4.4362e-04, 2.7680e-04,
        7.6848e-04, 8.3358e-04, 1.4606e-04, 4.0978e-04, 5.4827e-04, 9.8053e-04,
        1.2386e-03, 4.7033e-04, 5.7136e-04, 8.1583e-04, 2.0679e-04, 4.8940e-04,
        8.2072e-04, 8.2321e-04, 3.1064e-04, 7.4833e-04, 3.9084e-04, 6.8114e-04,
        8.6740e-04, 5.0638e-04, 4.0147e-04, 4.6162e-04, 2.4429e-04, 6.3472e-04,
        1.2304e-03, 5.5018e-04, 7.5616e-04, 8.1236e-04, 6.5152e-05, 1.3407e-03,
        2.9572e-04, 1.0832e-03, 2.7949e-04, 1.6986e-03, 6.2005e-04, 5.8327e-04,
        9.4670e-04, 1.1493e-03, 1.0620e-03, 1.9306e-04, 9.4717e-04, 2.6668e-03,
        4.0656e-04, 1.3107e-03, 1.5132e-03, 3.7775e-04, 4.4925e-04, 2.3469e-04,
        9.8950e-04, 7.2623e-04, 1.9631e-03, 7.5193e-04, 1.8921e-04, 1.5308e-03,
        3.2037e-04, 6.6031e-04, 3.9673e-04, 3.5825e-04, 7.6973e-04, 5.9700e-04,
        2.0222e-03, 1.7886e-03, 2.0155e-04, 2.6756e-04, 1.0500e-03, 3.0578e-03,
        7.4398e-04, 3.9579e-05, 7.4865e-04, 1.0825e-03, 3.9662e-04, 3.8195e-04,
        2.4565e-04, 1.4307e-03, 5.7377e-05, 2.8612e-04, 8.4914e-04, 5.1381e-04,
        3.8696e-04, 1.3414e-03, 5.3747e-04, 1.0561e-03, 4.3280e-04, 1.0387e-03,
        9.1099e-05, 1.8793e-04, 7.7651e-04, 2.2036e-04, 3.4838e-04, 8.5527e-04,
        1.1939e-03, 3.5306e-04, 1.2198e-03, 6.1848e-04, 3.5376e-04, 1.9609e-03,
        5.6574e-04, 9.2821e-04, 4.1961e-04, 6.2123e-04, 6.0672e-04, 1.1262e-03,
        4.6169e-04, 5.2917e-04, 9.5161e-05, 3.3037e-04, 7.4519e-04, 8.2242e-04,
        1.4825e-03, 2.1701e-04, 1.2578e-04, 5.2491e-04, 7.5332e-04, 3.2045e-04,
        1.7283e-04, 5.3152e-04, 1.4154e-04, 3.3939e-04, 1.7741e-04, 3.4618e-04,
        7.0713e-04, 1.5958e-04, 5.7034e-04, 5.7780e-04, 7.9846e-04, 9.4474e-04,
        7.2796e-04, 6.8771e-04, 5.9548e-04, 6.1876e-04, 2.1633e-04, 3.8243e-04,
        5.5684e-04, 7.3675e-04, 1.2088e-03, 2.1988e-03, 6.8123e-04, 9.2608e-04,
        8.4262e-04, 5.2372e-04, 4.9924e-04, 9.6386e-04, 2.1388e-03, 8.5692e-04,
        1.2203e-03, 8.1445e-04, 5.8334e-04, 6.2911e-04, 1.0180e-03, 1.0998e-03,
        1.0722e-03, 1.2562e-03, 1.2628e-03, 4.1866e-04, 1.2309e-03, 4.5148e-04,
        1.4395e-04, 4.9595e-04, 1.2537e-03, 3.1838e-04, 1.2335e-03, 2.0927e-04,
        3.3790e-04, 3.6357e-04, 1.8000e-03, 1.8874e-03, 4.1492e-04, 2.1633e-04,
        4.3373e-04, 1.3161e-03, 5.9004e-04, 7.6684e-04, 7.9188e-04, 6.3982e-04,
        3.6696e-04, 5.8788e-04, 4.6207e-04, 1.3589e-03, 7.4190e-04, 7.3031e-04,
        1.6395e-03, 3.0857e-04, 1.6361e-04, 4.7413e-04, 6.1554e-04, 4.9777e-04,
        9.5762e-04, 2.7785e-04, 1.8610e+05, 1.8251e+05]

def pooling(x):
    x = x.unsqueeze(0)
    x = adaptive_avg_pool1d(x, (256))
    x = x.squeeze()
    return x

class TCGAProstateLMDB(Dataset):
    def __init__(self, root, transforms=None):
        super().__init__(root)
        #self.root = root
        self.env = lmdb.open(root, map_size=1099511627776, readonly=True, lock=False)

        with self.env.begin(write=False) as txn:
            self.idxlist = [key.decode() for key in txn.cursor().iternext(keys=True, values=False)]

        #search_path = os.path.join(self.root, '**', '*.pt')
        #self.file_names = []
        #self.idxlist = []
        #for fn in self.file_names:
        #for fp in glob.iglob(search_path, recursive=True):
            #self.file_names.append(fp)
            #self.idxlist.append(os.path.basename(fp))
        self.file_names = self.idxlist
        self.transforms = transforms
        #self.mean = torch.tensor(mean)
        #self.std = torch.tensor(std)

        self.mean = torch.tensor(np.load(
            '/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_CPC/mean.npy'
            #'/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_Aug_CPC_LMDB_256/mean.npy'
        ))
        self.std = torch.tensor(np.load(
            '/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_CPC/std.npy'
            #'/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_Aug_CPC_LMDB_256/std.npy'
        ))


    def filepath(self):
        return self.file_names

    def len(self):
        return len(self.file_names)

    def get(self, idx):
        fp = self.file_names[idx]
        #data = torch.load(fp)
        with self.env.begin(write=False) as txn:
            data = txn.get(fp.encode())
            data = pickle.loads(data)

        if self.transforms is not None:
            data = self.transforms(data)

        data.patch_idx = torch.tensor([idx])
        #data.x = pooling(data.x)
        #print(data.x.shape)
        #data.x = torch.cat([data.x, data.pos], dim=1)
        data.x = (data.x - self.mean) / self.std

        data.x = data.x.float()
        data.x[torch.isnan(data.x)] = 0
        data.x[torch.isinf(data.x)] = 0
        return data


class TCGAProstateTestNormalize(Dataset):
    def __init__(self, root, transforms=None):
        super().__init__(root)
        self.num_nodes = 548
        self.root = root
        search_path = os.path.join(self.root, '**', '*.pt')
        self.file_names = []
        self.idxlist = []
#        self.labels = self.read_csv(csv_file)
        for fp in glob.iglob(search_path, recursive=True):
            #before = fp
            #fp = self.fix_label(fp)
            #if before != fp:
                #print(before, fp)
            self.file_names.append(fp)
            self.idxlist.append(os.path.basename(fp))
        self.transforms = transforms
        #self.mean = torch.tensor(mean)
        #self.std = torch.tensor(std)
        self.eps = 1e-7
        self.mean = torch.tensor(np.load(os.path.join(root, 'mean.npy')))
        #self.mean = torch.tensor(np.load(
        #    '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/stats/mean.npy' # 87.2 withtypes
        #))
        self.std = torch.tensor(np.load(os.path.join(root, 'std.npy')))
        #self.std = torch.tensor(np.load(
        #    #'/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_CPC/std.npy'
        #    '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/stats/std.npy' # 87.2 withtypes
        #))

        self.min = torch.tensor(np.load(os.path.join(root, 'min.npy')))
        #self.min = torch.tensor(np.load(
        #    '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/stats/min.npy' # 87.2 withtypes
        #))
        self.max = torch.tensor(np.load(os.path.join(root, 'max.npy')))
        #self.max = torch.tensor(np.load(
        #    #'/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_CPC/std.npy'
        #    '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/stats/max.npy' # 87.2 withtypes
        #))
        #self.mean = torch.tensor(np.load(
        #    '/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_Res50_withtype_Aug/mean.npy'
        #))
        #self.std = torch.tensor(np.load(
        #    '/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_Res50_withtype_Aug/std.npy'
        #))

    #def fix_label(self, fp):
    #    base_name = os.path.basename(fp)
    #    prefix, ext = base_name.split('_grade_')
    #    label = int(self.labels[prefix])
    #    if label >= 6:
    #        label = 2
    #    else:
    #        label = 1

    #    ext = str(label) + ext[1:]
    #    prefix = fp.split('_grade_')[0]
    #    fp = prefix + '_grade_' + ext
    #    return fp

    #def read_csv(self, csv_fp):
    #    image_names = []
    #    labels = []
    #    res = {}
    #    with open(csv_fp) as csvfile:
    #        reader = csv.DictReader(csvfile)
    #        for row in reader:
    #            image_name, label = row['image name'], row['gleason score']
    #            #image_names.append(image_name)
    #            #labels.append(label)
    #            res[image_name.split('.')[0]] = label

    #    return res

    def filepath(self):
        return self.file_names

    def len(self):
        return len(self.file_names)

    def get(self, idx):
        fp = self.file_names[idx]
        data = torch.load(fp)
        label = int(fp.split('_grade_')[1][0])
        #data.y = label
        #print(data.y, label)
        #print(111, data.y)
        data.y = int(data.y)
        assert data.y == label - 1
        if self.transforms is not None:
            data = self.transforms(data)

        data.patch_idx = torch.tensor([idx])
        #data.x = (data.x - self.mean) / self.std
        #data.x = data.x.float()

        data.x = self.normalize(data.x).float()


        data.x[torch.isnan(data.x)] = 0
        data.x[torch.isinf(data.x)] = 0

        #print(data.x.max())
        #print(data.x.min())

        return data

    def normalize(self, x):
        # normalize to (0, diff)
        diff = self.max - self.min + self.eps # avoid 0 division
        x = x - self.min  # larger than 0
        assert (x < 0).sum() == 0
        #print((x < 0).sum())
        mean = self.mean - self.min
        std = self.std

        # normalize to range (0, 1)
        #xmax = x.max()
        #xmin = x.min()
        # avoid 0 division
        x = x / diff
        #print(xmax, xmin, x.max(), x.min(), '33333333333333333333333', diff.max(), diff.min(), )
        #print(mean.max(), mean.min())
        #meanmin = mean.min()
        #meanmax = mean.max()
        # avoid 0 division
        mean = mean / diff
        #print(mean.max(), mean.min(), meanmin, meanmax)
        # avoid 0 division
        std = std / diff
        #print(std.max(), std.min(), 'fffffffffffffffffff')
        #print(mean.max(), mean.min(), std.max(), std.min())

        #print(std.max(), std.min(), 111111111)

        # normalize to 0 mean, 1 std
        #tmp = x - mean
        #print(tmp.min(), tmp.max(), 'ccccccccccccccc')
        #tmp[tmp < self.eps] = 0
        #x = tmp / (std + self.eps)
        #x = x - mean
        x = (x - mean) / (std + self.eps) # avoid 0 division
        #print(x.min(), x.max())
        #print((std < self.eps).sum(), id(std), '11')
        #print((x > 10).sum(), id(std))
        #print(x - mean)

        return x
    #def normalize(self, x):
    #    #[10, -3]   # max 11, min -5
    #    diff = self.max - self.min
    #    x = x - self.min  # larger than 0
    #    x = x / diff  # normalize to 0 - 1
    #    #x += self.max
    #    mean = (self.mean - self.min) / diff # normlized mean
    #    std = (self.std - self.min) / diff  # normalized std

    #    return (x - mean) / st

class TCGAProstate(Dataset):
    def __init__(self, root, transforms=None):
        super().__init__(root)
        self.root = root
        search_path = os.path.join(self.root, '**', '*.pt')
        self.file_names = []
        self.idxlist = []
        for fp in glob.iglob(search_path, recursive=True):
            self.file_names.append(fp)
            self.idxlist.append(os.path.basename(fp))
        self.transforms = transforms
        #self.mean = torch.tensor(mean)
        #self.std = torch.tensor(std)
        self.mean = torch.tensor(np.load(
            '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/mean.npy' # 87.2 withtypes
        ))
        self.std = torch.tensor(np.load(
            #'/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_CPC/std.npy'
            '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/std.npy' # 87.2 withtypes
        ))
        #self.min = torch.tensor(np.load(
        #    '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/stats/min.npy'
        #))
        #self.max = torch.tensor(np.load(
        #    '/data/hdd1/by/HGIN/acc872_prostate_5cropsAug/stats/max.npy'
        #))
        #self.mean = torch.tensor(np.load(
        #    '/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_Res50_withtype_Aug/mean.npy'
        #))
        #self.std = torch.tensor(np.load(
        #    '/data/smb/syh/PycharmProjects/CGC-Net/data_baiyu/TCGA_Prostate/Cell_Graph/5Crops_Res50_withtype_Aug/std.npy'
        #))

        # 87.2 min, max
        self.min = torch.tensor([4.3911e-04, 6.8368e-04, 1.2180e-03, 6.8484e-04, 9.1849e-04, 1.1716e-03,
        2.3755e-04, 5.0264e-04, 1.2642e-05, 1.6651e-04, 1.2123e-03, 1.2160e-03,
        1.1422e-03, 1.9037e-03, 5.5339e-05, 8.7072e-06, 4.7331e-04, 9.1563e-06,
        5.8562e-04, 5.2311e-04, 1.2937e-03, 9.3132e-05, 1.5212e-04, 1.5709e-03,
        3.3248e-04, 1.5466e-03, 2.2834e-03, 5.2915e-03, 1.8954e-03, 0.0000e+00,
        1.7043e-03, 3.8472e-04, 1.6548e-03, 2.8643e-04, 2.4463e-05, 9.4241e-05,
        1.0951e-04, 1.4391e-03, 1.2519e-04, 4.2508e-04, 4.1371e-05, 2.1444e-04,
        1.4712e-03, 3.5220e-03, 1.8214e-04, 2.3551e-03, 6.8322e-04, 6.4604e-04,
        1.5130e-04, 2.7018e-04, 1.4517e-04, 1.8277e-03, 8.7132e-04, 1.0634e-03,
        3.2717e-04, 1.7751e-03, 2.5075e-03, 1.1024e-03, 2.5484e-04, 7.8869e-04,
        1.7041e-03, 1.1143e-03, 2.1841e-04, 5.1133e-06, 1.5088e-04, 3.1986e-03,
        2.4037e-03, 2.9170e-05, 1.5594e-05, 2.7477e-05, 1.7103e-03, 3.6358e-03,
        8.9318e-04, 2.5046e-04, 1.1570e-03, 3.3594e-04, 1.2457e-03, 5.5588e-04,
        1.3985e-04, 3.4703e-03, 8.3797e-04, 8.2964e-05, 1.0671e-03, 5.0439e-04,
        1.6554e-04, 6.0888e-04, 1.3882e-03, 5.9330e-04, 9.0085e-04, 2.2378e-04,
        1.6597e-03, 9.1312e-04, 1.6969e-03, 1.2435e-03, 1.6145e-03, 7.0798e-05,
        4.8198e-06, 1.5580e-03, 1.3643e-03, 1.2646e-04, 1.3036e-03, 1.2960e-03,
        7.6109e-04, 4.8600e-06, 9.0845e-05, 8.9086e-05, 5.0711e-03, 3.9240e-05,
        5.9202e-05, 1.5360e-03, 9.5820e-04, 3.1015e-04, 5.1271e-03, 1.8517e-03,
        1.2229e-03, 6.1266e-04, 2.1815e-05, 3.6576e-04, 5.4904e-04, 4.7814e-04,
        9.1611e-05, 5.6251e-04, 1.0837e-03, 4.8022e-06, 2.0926e-04, 4.5248e-04,
        1.1040e-03, 1.8207e-03, 4.8254e-04, 9.5227e-04, 4.1687e-04, 1.4865e-04,
        4.0904e-04, 1.0328e-03, 1.0727e-03, 0.0000e+00, 2.5639e-03, 1.3471e-03,
        9.4161e-05, 3.9967e-03, 3.3732e-04, 9.3044e-04, 3.5673e-04, 1.4588e-05,
        1.3769e-03, 3.0957e-04, 2.3616e-04, 1.9704e-03, 2.8356e-04, 7.6077e-04,
        6.6868e-10, 2.7605e-04, 3.6025e-04, 1.5483e-03, 1.9172e-05, 2.1467e-03,
        5.6037e-04, 1.8351e-03, 8.9537e-04, 1.0047e-03, 1.8207e-03, 5.3902e-04,
        1.5384e-03, 2.0302e-04, 0.0000e+00, 2.1379e-03, 1.7659e-03, 1.2147e-03,
        6.3069e-05, 9.5164e-05, 1.0401e-02, 1.9207e-03, 6.4147e-04, 7.0544e-04,
        8.5025e-04, 1.5893e-03, 3.5785e-06, 4.9497e-05, 2.3360e-03, 2.0314e-03,
        9.4208e-05, 3.5759e-03, 2.4121e-03, 5.0099e-04, 9.8710e-06, 1.8537e-03,
        6.9938e-04, 6.9674e-06, 1.6454e-04, 9.8392e-04, 1.3487e-03, 9.3913e-04,
        4.5750e-04, 6.9039e-04, 9.9232e-04, 8.1631e-05, 1.3634e-04, 1.0806e-03,
        1.2012e-04, 7.1603e-04, 1.2179e-04, 1.4614e-03, 6.4218e-04, 1.2035e-03,
        1.2631e-03, 1.4316e-04, 1.1905e-03, 7.2947e-05, 2.1978e-04, 0.0000e+00,
        9.7702e-03, 4.4734e-05, 1.6409e-03, 1.9303e-03, 1.5455e-03, 9.4145e-04,
        1.6356e-03, 1.5364e-03, 7.5783e-04, 6.3521e-05, 1.3607e-03, 5.5455e-05,
        3.7650e-04, 1.7532e-03, 9.0236e-04, 5.7365e-04, 3.2395e-04, 4.8433e-03,
        9.8403e-05, 1.3357e-03, 5.3178e-04, 4.7572e-04, 1.2825e-03, 6.2680e-03,
        1.8637e-05, 1.4176e-03, 5.4545e-04, 5.1017e-04, 2.7942e-03, 6.4470e-05,
        7.3510e-04, 2.0467e-04, 2.7075e-05, 2.7709e-05, 5.4396e-05, 7.3546e-04,
        2.4062e-04, 1.7565e-03, 1.1201e-04, 1.2871e-03, 0.0000e+00, 1.0267e-03,
        1.2039e-03, 2.0118e-04, 2.8424e-04, 3.3560e-04, 1.1072e-03, 1.9145e-04,
        1.5209e-04, 1.6136e-03, 7.0504e-04, 2.0672e-04, 2.6373e-03, 1.5487e-04,
        7.2638e-05, 7.4461e-04, 9.5585e-06, 2.3233e-03, 2.5247e-04, 8.9952e-04,
        6.5953e-04, 1.3060e-03, 2.0010e-03, 7.0678e-05, 5.8312e-04, 3.9396e-04,
        2.0987e-04, 7.2214e-04, 1.0409e-03, 1.9427e-03, 1.3587e-03, 1.3631e-04,
        2.5535e-04, 1.2689e-03, 9.4776e-05, 1.3909e-03, 2.0543e-03, 1.4602e-03,
        5.9804e-06, 2.7373e-05, 4.6252e-04, 4.7033e-04, 2.1588e-03, 1.5971e-03,
        5.4869e-04, 1.2991e-03, 1.0012e-04, 9.6373e-04, 1.8919e-03, 1.8971e-03,
        2.8440e-04, 1.4979e-03, 1.7904e-04, 7.0519e-03, 1.0701e-05, 8.1401e-04,
        2.2424e-03, 8.6021e-04, 2.1475e-03, 6.3654e-03, 2.0216e-04, 2.8820e-03,
        1.7962e-03, 5.9540e-04, 1.0381e-03, 5.4201e-04, 2.8269e-05, 2.1404e-03,
        1.0345e-04, 3.6122e-04, 7.8842e-04, 1.2958e-04, 1.8811e-04, 1.3126e-03,
        5.2281e-05, 8.9026e-04, 1.3220e-03, 1.7333e-04, 5.6477e-04, 1.8275e-03,
        0.0000e+00, 3.4963e-04, 1.3801e-03, 2.2176e-04, 1.2027e-03, 2.0641e-03,
        1.6046e-05, 0.0000e+00, 1.6451e-03, 3.1559e-04, 4.7505e-04, 5.5129e-04,
        1.6215e-03, 3.9901e-04, 1.2704e-03, 1.8980e-03, 6.3488e-04, 2.7052e-04,
        1.8544e-04, 7.2621e-05, 6.0993e-04, 2.1378e-04, 1.5917e-03, 1.1367e-03,
        1.7240e-04, 1.4515e-03, 6.2564e-04, 1.0133e-04, 1.3518e-04, 9.6213e-04,
        5.5654e-04, 5.5153e-04, 1.0776e-05, 1.8696e-03, 4.1268e-03, 4.2193e-04,
        8.4849e-05, 1.8529e-04, 6.0453e-04, 3.4434e-04, 6.2133e-04, 2.4403e-03,
        2.0094e-03, 8.9923e-04, 6.1744e-04, 9.7741e-03, 1.1321e-03, 1.9696e-04,
        2.0985e-03, 5.4383e-03, 2.6045e-04, 1.2416e-03, 1.1262e-03, 1.6516e-03,
        5.7125e-04, 1.6690e-03, 5.6944e-05, 1.6754e-04, 3.8358e-04, 4.2565e-03,
        1.8540e-03, 1.0485e-04, 1.5539e-05, 4.5868e-04, 2.9716e-04, 2.0597e-04,
        9.6790e-05, 1.0016e-03, 2.0850e-04, 2.6841e-04, 1.4421e-04, 1.0706e-03,
        8.6557e-04, 1.5867e-03, 1.1373e-06, 2.4961e-04, 6.2808e-04, 5.5384e-04,
        1.8925e-03, 2.2976e-04, 3.0271e-04, 6.8478e-04, 2.1152e-04, 6.7793e-05,
        4.6312e-05, 5.8769e-04, 6.8363e-04, 6.6891e-04, 2.8810e-04, 3.6682e-04,
        1.7588e-04, 2.0028e-04, 8.1137e-06, 6.1727e-04, 9.4784e-04, 1.2559e-04,
        8.9565e-04, 1.4736e-04, 2.2951e-03, 1.6073e-04, 1.0907e-03, 9.7280e-05,
        2.2067e-03, 3.2879e-03, 3.6894e-03, 2.1289e-03, 5.7497e-04, 2.6089e-04,
        1.0466e-03, 4.5297e-03, 1.2509e-04, 1.9233e-04, 5.1275e-04, 2.4909e-03,
        3.1830e-03, 3.2200e-03, 2.3511e-03, 4.5991e-04, 1.8379e-04, 6.8702e-04,
        3.1808e-03, 1.5642e-04, 7.3930e-04, 1.3253e-03, 1.2882e-04, 2.6747e-03,
        2.7125e-04, 1.1906e-04, 9.9568e-04, 2.7428e-04, 1.4823e-03, 1.4053e-03,
        9.4634e-05, 2.0129e-03, 1.4470e-03, 1.2294e-03, 6.5393e-04, 3.9513e-04,
        1.0779e-04, 3.8318e-04, 4.8101e-05, 4.2584e-04, 5.8564e-04, 1.4444e-04,
        6.6562e-04, 3.4298e-05, 2.5238e-05, 3.3217e-04, 1.4068e-04, 5.7234e-04,
        4.8319e-05, 9.0098e-04, 6.9418e-04, 1.8574e-03, 7.6938e-04, 3.4328e-03,
        5.4100e-05, 1.6815e-03, 5.1753e-04, 8.1333e-05, 6.5604e-04, 1.7154e-03,
        7.4586e-05, 5.3254e-05, 1.2480e-04, 1.1156e-03, 1.6697e-04, 1.1010e-04,
        9.1878e-04, 1.0455e-03, 3.1332e-05, 7.3845e-04, 5.2642e-04, 3.8788e-05,
        1.6549e-03, 6.6887e-04, 1.4891e-03, 1.2090e-03, 1.7435e-04, 1.3559e-04,
        5.0122e-04, 1.8086e-04])
        self.max = torch.tensor([0.1454, 0.0776, 0.1033, 1.0961, 0.3344, 0.1744, 0.4317, 0.0958, 0.1641,
        0.2930, 0.4661, 0.0828, 0.1408, 0.1744, 0.4158, 0.3297, 0.4540, 0.1160,
        0.3178, 0.1480, 0.5083, 0.1678, 0.1812, 0.3991, 0.2250, 0.0631, 0.0425,
        0.3196, 0.2953, 0.4453, 0.5666, 0.0863, 0.1541, 0.4719, 0.2327, 0.6645,
        0.2875, 0.3254, 0.2023, 0.1361, 0.3531, 0.1414, 0.5442, 0.3842, 0.3324,
        0.1505, 0.0833, 0.0161, 0.2175, 0.4956, 0.1135, 0.0623, 0.2493, 0.2092,
        0.5868, 0.1435, 0.6975, 0.1546, 0.3400, 0.3449, 0.1237, 0.2691, 0.0227,
        0.4442, 0.0662, 0.2329, 0.2350, 0.2471, 0.2147, 0.1293, 0.0747, 0.3588,
        0.6358, 0.1742, 0.3911, 0.2135, 0.3698, 0.1529, 0.1983, 0.5192, 0.5220,
        0.1041, 0.1903, 0.2215, 0.1979, 0.0374, 0.1572, 0.1107, 0.1861, 0.0467,
        0.1207, 0.1342, 0.5357, 0.3256, 0.1829, 0.5822, 0.2299, 0.8619, 0.2303,
        0.0366, 0.0969, 0.1634, 0.1646, 0.0886, 0.1033, 0.3892, 0.2269, 0.3000,
        0.3468, 0.7216, 0.5435, 0.2583, 0.1375, 0.0328, 0.1376, 0.1181, 0.4950,
        0.1964, 0.3586, 0.2679, 0.0555, 0.1797, 0.1527, 0.1490, 0.1591, 0.1588,
        0.1644, 0.0359, 0.2165, 0.1801, 0.2159, 0.3141, 0.3428, 0.2002, 0.0480,
        0.2543, 0.1536, 0.2038, 1.1338, 0.3717, 0.2055, 0.5004, 0.2507, 0.6223,
        0.3533, 0.5152, 0.4620, 0.6844, 0.0994, 0.1883, 0.2537, 0.2571, 0.1219,
        0.1421, 0.2004, 0.1633, 0.1520, 0.0617, 0.7185, 0.0242, 0.0439, 0.8852,
        0.0422, 0.2563, 0.1992, 0.0938, 0.4831, 0.0784, 0.0994, 0.3854, 0.3479,
        0.3658, 0.0695, 0.2303, 0.0999, 0.2220, 0.3202, 0.2175, 0.2074, 0.3997,
        0.2266, 0.1704, 0.1524, 0.0950, 0.4221, 0.0051, 0.0591, 0.2573, 0.0432,
        0.0992, 0.2094, 0.6000, 0.2111, 0.1154, 0.2934, 0.3930, 0.2193, 0.2899,
        0.0063, 0.2492, 0.3504, 0.1974, 0.1710, 0.0926, 0.0371, 0.3771, 0.5504,
        0.1937, 0.3583, 0.5605, 0.2913, 0.0567, 0.1487, 0.1044, 0.1778, 0.0186,
        0.3625, 0.0023, 0.3489, 0.2598, 0.4433, 0.1623, 0.1516, 0.0872, 0.3048,
        0.1895, 0.6487, 0.2070, 0.3548, 0.2793, 0.0756, 0.3838, 0.2343, 0.4318,
        0.1029, 0.4382, 0.3752, 0.1512, 0.3434, 0.4145, 0.0261, 0.3143, 0.3880,
        0.1645, 0.0972, 0.3850, 0.2349, 0.2532, 0.0714, 0.1847, 0.4694, 0.4447,
        0.2916, 0.0616, 0.0748, 0.4691, 0.1496, 0.1936, 0.3151, 0.0655, 0.0954,
        0.4632, 0.1923, 0.1978, 0.1169, 0.1182, 0.7000, 0.1005, 0.1190, 0.2258,
        0.3179, 0.0434, 0.2941, 0.2444, 0.3773, 0.2600, 0.1671, 0.5130, 0.1909,
        0.3092, 0.2105, 0.2643, 0.1730, 0.0248, 0.1216, 0.2092, 0.1591, 0.1810,
        0.3249, 0.0399, 0.2929, 0.0741, 0.0688, 0.2930, 0.5038, 0.1000, 0.1618,
        0.5649, 0.4888, 0.3071, 0.2001, 0.2823, 0.1043, 0.4661, 0.1936, 0.1328,
        0.5923, 0.1489, 0.6320, 0.1740, 0.2161, 0.1234, 0.2678, 0.0888, 0.5592,
        0.5433, 0.2965, 0.3451, 0.0881, 0.3278, 0.1593, 0.3041, 0.0903, 0.6649,
        0.0882, 0.2605, 0.1684, 0.0275, 0.3241, 0.1779, 0.3146, 0.1728, 0.1203,
        0.1236, 0.0444, 0.1362, 0.2765, 0.1976, 0.2353, 0.1871, 0.1329, 0.1265,
        0.5969, 0.2508, 0.0920, 0.0131, 0.2281, 0.1600, 0.4332, 0.3579, 0.1761,
        0.1001, 0.1750, 0.0930, 0.1389, 0.4175, 0.1276, 1.3754, 1.5592, 0.3921,
        0.1615, 0.3723, 0.1860, 0.0159, 0.8638, 0.7404, 0.0917, 1.1428, 0.1075,
        0.1122, 0.1042, 0.0237, 0.1988, 0.1258, 0.1197, 0.2525, 0.1948, 0.6208,
        0.1017, 0.4094, 0.0686, 0.3821, 0.2028, 0.1167, 0.9050, 0.3113, 0.0268,
        0.0707, 0.3087, 0.3702, 0.1487, 0.0218, 0.1880, 0.1825, 0.0748, 0.1853,
        0.1567, 0.1246, 0.0623, 0.0864, 0.3296, 0.0624, 0.2576, 0.0314, 0.1901,
        0.8994, 0.1828, 0.2818, 0.0986, 0.2173, 0.4328, 0.2622, 0.2726, 0.1797,
        0.3694, 0.2115, 0.3628, 0.1009, 0.0622, 0.5662, 0.0822, 0.1335, 0.0522,
        0.4087, 0.1361, 0.1355, 0.2106, 0.1094, 0.1202, 0.0683, 0.0779, 0.1499,
        0.4143, 0.1162, 0.0830, 0.3379, 0.2604, 0.1370, 0.0127, 0.2035, 0.0074,
        0.0763, 0.0127, 0.3725, 0.4699, 0.3170, 0.0764, 0.1807, 0.1062, 0.3144,
        0.1376, 0.1702, 0.1220, 0.4983, 0.0632, 0.1623, 0.1065, 0.7297, 0.2602,
        0.3364, 0.2020, 0.9879, 0.1066, 0.1085, 0.2179, 0.2538, 0.5069, 0.3034,
        0.1178, 0.6789, 0.3680, 0.7152, 0.0981, 0.1296, 0.3380, 0.1942, 0.3453,
        0.1606, 0.2748, 0.2738, 0.4135, 0.4349, 0.8237, 0.3847, 0.1343, 0.0667,
        0.1710, 0.1282, 0.3719, 0.4881, 0.1038, 0.0637, 0.1244, 1.4855, 0.1266,
        0.2390, 0.1750, 0.0833, 0.2014, 0.1649, 0.5773, 0.2766, 0.1092, 0.1950,
        0.7463, 0.1273, 0.1812, 0.1976, 0.6087, 0.1492, 0.0450, 0.1874])

    def filepath(self):
        return self.file_names

    def len(self):
        return len(self.file_names)

    def get(self, idx):
        fp = self.file_names[idx]
        data = torch.load(fp)
        if self.transforms is not None:
            data = self.transforms(data)

        data.patch_idx = torch.tensor([idx])
        #data.x = (data.x - self.mean) / self.std
        #data.x = data.x.float()

        data.x = self.normalize(data.x).float()


        data.x[torch.isnan(data.x)] = 0
        data.x[torch.isinf(data.x)] = 0

        return data

    def normalize(self, x):
        #[10, -3]   # max 11, min -5
        diff = self.max - self.min
        x = x - self.min  # larger than 0
        x = x / diff  # normalize to 0 - 1
        #x += self.max
        mean = (self.mean - self.min) / diff # normlized mean
        std = (self.std - self.min) / diff  # normalized std

        return (x - mean) / std

#class CRC(Dataset):
#    def __init__(self, root, cv, data_set, transforms=None):
#        super().__init__(root)
#        cv = 'fold_{}'.format(cv)
#        self.root = root
#        search_path = os.path.join(self.root, '**', '*.pt')
#        self.file_names = []
#        self.idxlist = []
#        for fp in glob.iglob(search_path, recursive=True):
#            if data_set == 'train':
#                if cv not in fp:
#                    self.file_names.append(fp)
#                    self.idxlist.append(os.path.basename(fp))
#            elif data_set == 'test':
#                if cv in fp:
#                    self.file_names.append(fp)
#                    self.idxlist.append(os.path.basename(fp))
#            else:
#                raise ValueError('wrong value')
#
#        self.transforms = transforms
#        #self.mean = torch.tensor(mean)
#        #self.std = torch.tensor(std)
#        #self.coord_mean =
#
#        # min, max of unet vgg
#        self.min = torch.tensor([-0.0199, -0.0183, -0.0149, -0.0160, -0.0201, -0.0251, -0.0141, -0.0180,
#        -0.0119, -0.0061, -0.0116, -0.0071, -0.0183, -0.0280, -0.0183, -0.0271])
#        self.max = torch.tensor([0.0027, 0.0058, 0.0096, 0.0111, 0.0080, 0.0009, 0.0073, 0.0097, 0.0134,
#        0.0152, 0.0121, 0.0116, 0.0087, 0.0087, 0.0079, 0.0082])
#        #self.min = torch.tensor([9.0000e+01, 7.1388e+00, 7.2445e-02, 6.8259e-02, 1.1786e-01, 1.1679e-01,
#        #1.1255e-01, 6.5754e-02, 7.1361e-02, 5.6361e-02, 7.1411e-02, 6.7237e-02,
#        #6.6426e-02, 5.8134e-02, 4.7020e-02, 5.6861e-02])
#        #self.max = torch.tensor([6.1515e+03, 2.6721e+01, 2.7360e-01, 2.0685e-01, 3.4070e-01, 4.1898e-01,
#        #3.9159e-01, 1.2634e-01, 1.4812e-01, 3.1718e-01, 1.9040e-01, 1.3550e-01,
#        #1.8788e-01, 1.6921e-01, 1.6068e-01, 1.3820e-01])
#        self.num_nodes = 3367
#
#    def normalize(self, x):
#        #[10, -3]   # max 11, min -5
#        diff = self.max - self.min
#        x = x - self.min  # larger than 0
#        x = x / diff  # normalize to 0 - 1
#        #x += self.max
#        mean = (self.mean - self.min) / diff # normlized mean
#        std = (self.std - self.min) / diff  # normalized std
#
#        return (x - mean) / std
#
#    def filepath(self):
#        return self.file_names
#
#    def len(self):
#        return len(self.file_names)
#
#    def get(self, idx):
#        fp = self.file_names[idx]
#        data = torch.load(fp)
#        #print(data)
#        #if self.transforms is not None:
#        #    data = self.transforms(data)
#
#        #data.x[torch.isnan(data.x)] = 0
#        #data.x[torch.isinf(data.x)] = 0
#        data.patch_idx = torch.tensor([idx])
#        #print(data.x.mean(), fp, data.x)
#        #print(data.x[torch.isnan(data.x)])
#        #data.x = torch.cat([data.x, data.pos], dim=1)
#        #print(data.x.shape)
#        #print(self.mean)
#        #print(torch.isnan(data.x).sum())
#        #print(torch.isnan(data.x))
#        #print(data.x.mean())
#        #print(data.x.max(), data.x.min(), 'befre', idx)
#        #data.x = (data.x - self.mean[:16]) / self.std[:16]
#        #data.x = (data.x - self.mean) / self.std
#
#        #####################
#        #imagenet pretrain
#        #mean = torch.tensor((1792.9, 1782.7))
#        #std = torch.tensor((1.0348e+03, 1.0332e+03))
#        #data.x = data.x - 0.4
#        #data.pos = (data.pos - mean) / std
#        #data.x = torch.cat([data.x, data.pos], dim=1)
#        ##########################
#        #data.x = data.x.float()
#        data.path = fp
#        data.x = self.normalize(data.x).float()
#        #print(data.x.max(), data.x.min())
#
#        #print(self.mean, self.std)
#        #print(data.x)
#        #print(data.x, 'before')
#        #data.x = (data.x - self.mean) / self.std
#        #print(data.x.max(), data.x.min(), 'after', idx)
#        #print(data.x)
#        #print(data, data.y)
#
#        return data


        #self.processed_dir = root
        #print(self.processed_dir)
#setting = CrossValidSetting()
#print(setting.root)
#dataset = TCGAProstate('/data/smb/syh/pycharmprojects/cgc-net/data_res50/proto/fix_avg_cia_knn/0')
#print(len(dataset))
#print(dataset[33])
